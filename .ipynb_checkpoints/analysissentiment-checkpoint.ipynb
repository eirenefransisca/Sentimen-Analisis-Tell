{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# To open dialog download:\n",
    "# nltk.download();\n",
    "# # To downlaod just stopwords:\n",
    "# nltk.download('stopwords');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['polarity', 'text']\n",
      "<bound method NDFrame.head of      polarity                                               text\n",
      "0       anger       Kang angkot seenaknya banget narik ongkos -_\n",
      "1      netral  \"F yang 20 - 25 pc dong, need F w bi nihh yg p...\n",
      "2        love  \"Kenapa sekalipun dia cowo yg cuek, judes dan ...\n",
      "3         sad  Gue mancing2 cewek semalem.. Meskipun buat cee...\n",
      "4      netral  Ada yg pake cream skin id'e ? Sharing pengalam...\n",
      "...       ...                                                ...\n",
      "7989      sad  gatau kenapa akhir-akhir sensitif bgt bahas ap...\n",
      "7990   netral  \"Gue move sm anak tell 4 kali apa 3 kali ya, a...\n",
      "7991   netral                           sbm itb emang mahal ya??\n",
      "7992      joy          DOH AJIG ETA CILOR HANEUT2 NGEUNAH SIGANA\n",
      "7993      sad  gue suka anak kecil dibilang pedofil sm doi eh...\n",
      "\n",
      "[7994 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "datasettell = pd.read_csv('dataset_tell_rapidminer.csv',error_bad_lines=False,\n",
    "                  sep=\";\", encoding='cp1252')\n",
    "print (list(datasettell))\n",
    "print(datasettell.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            kang angkot seenaknya banget narik ongkos -_\n",
      "1       \"f yang 20 - 25 pc dong, need f w bi nihh yg p...\n",
      "2       \"kenapa sekalipun dia cowo yg cuek, judes dan ...\n",
      "3       gue mancing2 cewek semalem.. meskipun buat cee...\n",
      "4       ada yg pake cream skin id'e ? sharing pengalam...\n",
      "                              ...                        \n",
      "7989    gatau kenapa akhir-akhir sensitif bgt bahas ap...\n",
      "7990    \"gue move sm anak tell 4 kali apa 3 kali ya, a...\n",
      "7991                             sbm itb emang mahal ya??\n",
      "7992            doh ajig eta cilor haneut2 ngeunah sigana\n",
      "7993    gue suka anak kecil dibilang pedofil sm doi eh...\n",
      "Name: text, Length: 7994, dtype: object\n"
     ]
    }
   ],
   "source": [
    "datasettell['text'] = datasettell['text'].str.lower()\n",
    "print(datasettell['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kang angkot seenaknya banget narik ongkos -_\n"
     ]
    }
   ],
   "source": [
    "example_text = datasettell.iloc[0]\n",
    "print(example_text['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kang', 'angkot', 'seenaknya', 'banget', 'narik', 'ongkos', '-_']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "print (nltk.word_tokenize(example_text['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_tokens(row):\n",
    "    text = row['text']\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # taken only words (not punctuation)\n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    return token_words\n",
    "\n",
    "datasettell['words'] = datasettell.apply(identify_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_list(row):\n",
    "    my_list = row['words']\n",
    "    stemmed_list = [stemming.stem(word) for word in my_list]\n",
    "    return (stemmed_list)\n",
    "\n",
    "datasettell['stemmed_words'] = datasettell.apply(stem_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [kang, angkot, seenaknya, banget, narik, ongko]\n",
      "1       [f, yang, pc, dong, need, f, w, bi, nihh, yg, ...\n",
      "2       [kenapa, sekalipun, dia, cowo, yg, cuek, jude,...\n",
      "3       [gue, cewek, semalem, meskipun, buat, ceesan, ...\n",
      "4       [ada, yg, pake, cream, skin, id, e, share, pen...\n",
      "                              ...                        \n",
      "7989    [gatau, kenapa, sensitif, bgt, baha, apa, baha...\n",
      "7990    [gue, move, sm, anak, tell, kali, apa, kali, y...\n",
      "7991                         [sbm, itb, emang, mahal, ya]\n",
      "7992             [doh, ajig, eta, cilor, ngeunah, sigana]\n",
      "7993    [gue, suka, anak, kecil, dibilang, pedofil, sm...\n",
      "Name: stem_meaningful, Length: 7994, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "#stops = set(stopwords.words(\"indonesian\"))\n",
    "stopwords = pd.read_csv('tb_katadasar.csv')\n",
    "\n",
    "def remove_stops(row):\n",
    "    my_list = row['stemmed_words']\n",
    "    meaningful_words = [w for w in my_list if not w in stopwords]\n",
    "    return (meaningful_words)\n",
    "\n",
    "datasettell['stem_meaningful'] = datasettell.apply(remove_stops, axis=1)\n",
    "print(datasettell['stem_meaningful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                kang angkot seenaknya banget narik ongko\n",
      "1       f yang pc dong need f w bi nihh yg pent sale n...\n",
      "2       kenapa sekalipun dia cowo yg cuek jude dan bod...\n",
      "3       gue cewek semalem meskipun buat ceesan atau ve...\n",
      "4       ada yg pake cream skin id e share pengalamanny...\n",
      "                              ...                        \n",
      "7989    gatau kenapa sensitif bgt baha apa baha apa na...\n",
      "7990       gue move sm anak tell kali apa kali ya au lupa\n",
      "7991                               sbm itb emang mahal ya\n",
      "7992                    doh ajig eta cilor ngeunah sigana\n",
      "7993    gue suka anak kecil dibilang pedofil sm doi eh...\n",
      "Name: processed, Length: 7994, dtype: object\n",
      "['polarity', 'text', 'words', 'stemmed_words', 'stem_meaningful', 'processed']\n"
     ]
    }
   ],
   "source": [
    "def rejoin_words(row):\n",
    "    my_list = row['stem_meaningful']\n",
    "    joined_words = ( \" \".join(my_list))\n",
    "    return joined_words\n",
    "\n",
    "datasettell['processed'] = datasettell.apply(rejoin_words, axis=1)\n",
    "\n",
    "print(datasettell['processed'])\n",
    "print(list(datasettell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [ 'text','words','stemmed_words','stem_meaningful']\n",
    "datasettell= datasettell.drop(cols_to_drop, axis='columns')\n",
    "\n",
    "datasettell.to_excel('datasettell_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
